{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><span style='color:blue'> MNIST: Full network with patch-centering   </center></h1></span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here try to replicate the experiments as detailed in Mairal and al's 2014 paper on Convolutional Kernel Methods.\n",
    "\n",
    "The convolutional network is a __CKN__ object which comprises of $K$ different layers (or cells, since these cells are all trained independently of the others). Each cell is a __ Cell__ object, parameterized by a number of filters (the greater the number of filters, the better the linear kernel approximation).\n",
    "\n",
    "When training the network, each cell is trained as follows:\n",
    "\n",
    "__INPUT__: input_map: input data (contrast-normalized(?) image patches for instance for MNIST)\n",
    "+ (1) extract patches from input map (by concatenating neighboring pixel input). Normalize the patches so that they all have unit norm. (Keep the orginal norms in memory, in Cell.norms).\n",
    "+ (2) apply dimensionality reduction to these large patches (RobustScaler+PCA), so that the whole thing remains computable\n",
    "+ (3) initalize new filters with Kmeans\n",
    "+ (4) train W and eta (parameters of the cell) on a subset of the data. The function check_convergence() allows to check how well we are doing in terms of approximating the kernel.\n",
    "+ (5) call get_activation_map() to compute the activation of each patch\n",
    "\n",
    "__OUTPUT__: activation map of patches centered at each pixel with respect to the filter W\n",
    "\n",
    "From there, to compute the activation map of any new image, we simply have to:\n",
    "+ (1) extract the patches from the image\n",
    "+ (2) call propagate_through_network(X). This function at each layer applies the Kernel to compute similarities between patches. \n",
    "\n",
    "Here, we try to first center the MNIST data before applying the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from CKN import *\n",
    "from Nystrom import *\n",
    "from image_processing_utils import *\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inds=range(60000)\n",
    "import random\n",
    "random.seed(2017)\n",
    "random.shuffle(inds)\n",
    "\n",
    "test=train_loader.dataset.train_data[inds[:3000],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_labels=train_loader.dataset.train_labels[torch.LongTensor(inds[:3000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 9\n",
       " 6\n",
       "â‹® \n",
       " 1\n",
       " 1\n",
       " 5\n",
       "[torch.LongTensor of size 3000]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=test\n",
    "data=1.0/255*data.type(torch.FloatTensor)\n",
    "#data2=data-torch.mean(data.view(-1,data.size()[1]*data.size()[2]),0).view(28,28)\n",
    "#S=torch.std(data2.view(-1,data.size()[1]*data.size()[2]),0)\n",
    "#S[S==0]=1\n",
    "#data2=1.0/255*data2.view(-1,data.size()[1]*data.size()[2])\n",
    "#data2=data2.view(-1,28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### contrast normalize\n",
    "n_d,p_dim,_=data.size()\n",
    "#norm=torch.max(torch.sum(data.view(n_d,-1)**2,1),torch.Tensor([0.00001]))\n",
    "#data=torch.div(data.view(n_d,-1),norm.view(n_d,1).expand(n_d,p_dim**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=data.view(n_d,p_dim,p_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 28, 28])\n",
      "patches extracted with size  torch.Size([784, 3000, 25])\n",
      "patches normalized extracted with size  torch.Size([784, 3000, 25])\n",
      "Training patches have been standardized and have size torch.Size([784, 3000, 25])\n",
      "[[0, 366, 642], [0, 12, 326], [0, 471, 660], [0, 524, 720], [0, 721, 223], [0, 47, 559], [0, 173, 695], [0, 335, 280], [0, 92, 49], [0, 506, 196]]\n",
      "('sel', torch.Size([90000, 2, 25]))\n",
      "('The data has size', torch.Size([784, 3000, 25]))\n",
      "('all okay', True)\n",
      "('The variance is: ', 5.4945039749145508)\n",
      "('size input: ', torch.Size([90000, 2, 25]))\n",
      "Epoch: 0  Mean loss: \n",
      "1.00000e-02 *\n",
      "  1.9249\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.1194081306\n",
      "Epoch: 1  Mean loss: \n",
      "1.00000e-03 *\n",
      "  6.1131\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.2693510056\n",
      "Epoch: 2  Mean loss: \n",
      "1.00000e-03 *\n",
      "  4.6325\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.1869580746\n",
      "Epoch: 3  Mean loss: \n",
      "1.00000e-03 *\n",
      "  3.7634\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.4093430042\n",
      "Epoch: 4  Mean loss: \n",
      "1.00000e-03 *\n",
      "  3.2277\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  14.8872289658\n",
      "Epoch: 5  Mean loss: \n",
      "1.00000e-03 *\n",
      "  2.8586\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  15.2060709\n",
      "Epoch: 6  Mean loss: \n",
      "1.00000e-03 *\n",
      "  2.5851\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  13.8390419483\n",
      "Epoch: 7  Mean loss: \n",
      "1.00000e-03 *\n",
      "  2.3716\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  15.8522050381\n",
      "Epoch: 8  Mean loss: \n",
      "1.00000e-03 *\n",
      "  2.1984\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  11.740555048\n",
      "Epoch: 9  Mean loss: \n",
      "1.00000e-03 *\n",
      "  2.0536\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  11.6194109917\n",
      "Epoch: 10  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.9303\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  13.7225849628\n",
      "Epoch: 11  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.8236\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  14.1580440998\n",
      "Epoch: 12  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.7302\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.8285419941\n",
      "Epoch: 13  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.6476\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.2353720665\n",
      "Epoch: 14  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.5740\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  11.9094259739\n",
      "Epoch: 15  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.5080\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.246227026\n",
      "Epoch: 16  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.4483\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  11.6736760139\n",
      "Epoch: 17  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.3941\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.7764101028\n",
      "Epoch: 18  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.3446\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.8922810555\n",
      "Epoch: 19  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.2992\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.2467811108\n",
      "Epoch: 20  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.2574\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.1199679375\n",
      "Epoch: 21  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.2187\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.0733778477\n",
      "Epoch: 22  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.1829\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.8681790829\n",
      "Epoch: 23  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.1497\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  15.706589222\n",
      "Epoch: 24  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.1187\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  13.6021239758\n",
      "Epoch: 25  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.0898\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.9729189873\n",
      "Epoch: 26  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.0628\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  15.2565889359\n",
      "Epoch: 27  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.0374\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  17.4504759312\n",
      "Epoch: 28  Mean loss: \n",
      "1.00000e-03 *\n",
      "  1.0136\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  12.6383039951\n",
      "Epoch: 29  Mean loss: \n",
      "1.00000e-04 *\n",
      "  9.9119\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  14.0970759392\n",
      "Epoch: 30  Mean loss: \n",
      "1.00000e-04 *\n",
      "  9.7002\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  13.8330979347\n",
      "Epoch: 31  Mean loss: \n",
      "1.00000e-04 *\n",
      "  9.4998\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  15.2649328709\n",
      "Epoch: 32  Mean loss: \n",
      "1.00000e-04 *\n",
      "  9.3100\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.8418779373\n",
      "Epoch: 33  Mean loss: \n",
      "1.00000e-04 *\n",
      "  9.1300\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.3086469173\n",
      "Epoch: 34  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.9591\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.6862649918\n",
      "Epoch: 35  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.7968\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  16.254224062\n",
      "Epoch: 36  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.6425\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.4494478703\n",
      "Epoch: 37  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.4955\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  21.9176578522\n",
      "Epoch: 38  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.3554\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  20.1252839565\n",
      "Epoch: 39  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.2219\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.3308501244\n",
      "Epoch: 40  Mean loss: \n",
      "1.00000e-04 *\n",
      "  8.0946\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  20.1959190369\n",
      "Epoch: 41  Mean loss: \n",
      "1.00000e-04 *\n",
      "  7.9731\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  20.7409710884\n",
      "Epoch: 42  Mean loss: \n",
      "1.00000e-04 *\n",
      "  7.8571\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  19.9612898827\n",
      "Epoch: 43  Mean loss: \n",
      "1.00000e-04 *\n",
      "  7.7461\n",
      "[torch.FloatTensor of size 1]\n",
      "  time per epoch:  24.4704518318\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1bfa43ea45de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msize_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCKN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_patches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize_patch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubsampling_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Cell.fit_LBFGS(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cdonnat/Dropbox/Pattern-analysis/pattern_detection/CKN.pyc\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatches_given\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0moutput_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activation_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/Dropbox/Pattern-analysis/pattern_detection/Nystrom.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, init, patches_given)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0moverall_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net=CKN()\n",
    "size_patch=5\n",
    "net=CKN(n_components=[50,200],n_layers=2,iter_max=50,n_patches=[size_patch,2],subsampling_factors=[2,2],batch_size=[60,60])#Cell.fit_LBFGS(X)\n",
    "net.train_network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(net.Kernel[0].eta.data)\n",
    "self=net\n",
    "sb.heatmap(net.Kernel[0].W.data.numpy())\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.Kernel[0].convergence_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.Kernel[1].convergence_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([ u.numpy() for u in net.Kernel[0].training_loss])\n",
    "#plt.plot([ u.numpy() for u in net.Kernel[1].training_loss],c='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(net.Kernel[0].output.size())\n",
    "sb.heatmap(net.Kernel[0].output[100,:100,:].numpy())\n",
    "print(X_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, pipeline\n",
    "from sklearn.kernel_approximation import (RBFSampler,\n",
    "                                          Nystroem)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "#X=net.Kernel[0].output\n",
    "X=net.Kernel[0].get_activation_map()\n",
    "n_p,n_d,p_dim=X.size()\n",
    "print(X.size())\n",
    "X=X.permute(1,0,2)\n",
    "print(X.size())\n",
    "\n",
    "pca_mnis=PCA(n_components=15,whiten=True)\n",
    "pca_mnis.fit(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "print(X.contiguous().view(n_d, n_p*p_dim).size())\n",
    "\n",
    "print(X.contiguous().size())\n",
    "X2=pca_mnis.transform(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "\n",
    "kernel_svm = svm.SVC(gamma=0.2)\n",
    "\n",
    "kernel_svm.fit(X2, X_labels.numpy())\n",
    "kernel_svm_score = kernel_svm.score(X2, X_labels.numpy())\n",
    "print(kernel_svm_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=train_loader.dataset.train_data[torch.LongTensor(inds[3000:6000])]\n",
    "X_test_labels=train_loader.dataset.train_labels[torch.LongTensor(inds[3000:6000])]\n",
    "\n",
    "X_test=1.0/255*X_test.type(torch.FloatTensor)\n",
    "print(X_test.size())\n",
    "norm_test=torch.max(torch.sum(X_test.view(n_d,-1)**2,1),torch.Tensor([0.00001]))\n",
    "print(norm_test.size())\n",
    "n_d,p,_=X_test.size()\n",
    "normalize=False\n",
    "if normalize:\n",
    "    X_test=torch.div(X_test.view(n_d,-1),norm_test.view(n_d,1).expand(n_d,p**2))\n",
    "print(X_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test=torch.div(X_test.view(n_d,-1),norm_test.view(n_d,1,1).expand(n_d,X_test.size()[1]*X_test.size()[2]))\n",
    "X_test=X_test.view(n_d,p,p)\n",
    "print(X_test.size())\n",
    "#X_test=extract_patches_from_image(X_test,size_patch)\n",
    "#print(X_test.size())\n",
    "#n_p2,n_d,_,_=X_test.size()\n",
    "#X_test=X_test.view(n_p2,n_d,-1)\n",
    "print(X_test.size())\n",
    "output_test=net.propagate_through_network(X=X_test,patches_given=False)\n",
    "\n",
    "#n_p,n_d,p_dim=X_test.size()\n",
    "XX=output_test\n",
    "print( 'XX size',XX.size())\n",
    "XX=XX.permute(1,0,2)\n",
    "print(XX.size())\n",
    "X_test1=pca_mnis.transform(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "X_test=pca_mnis.transform(XX.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "\n",
    "kernel_svm_score = kernel_svm.score(X_test, X_test_labels.numpy())\n",
    "print(kernel_svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_map=net.Kernel[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norms=input_map.norm(p=2,dim=2)\n",
    "input_map=normalize_output(input_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_map2=net.Kernel[1].get_activation_map( X=input_map,norms=norms,verbose=True\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_map2=net.Kernel[1].standardize.transform(input_map.view(n_p*n_d,-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_map.view(n_p*n_d,-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

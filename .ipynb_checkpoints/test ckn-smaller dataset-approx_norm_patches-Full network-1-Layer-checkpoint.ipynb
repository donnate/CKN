{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from CKN import *\n",
    "from Nystrom import *\n",
    "from image_processing_utils import *\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inds=range(60000)\n",
    "import random\n",
    "random.seed(2017)\n",
    "random.shuffle(inds)\n",
    "\n",
    "test=train_loader.dataset.train_data[inds[:3000],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_labels=train_loader.dataset.train_labels[torch.LongTensor(inds[:3000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 9\n",
       " 6\n",
       "â‹® \n",
       " 1\n",
       " 1\n",
       " 5\n",
       "[torch.LongTensor of size 3000]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=test\n",
    "data=1.0/255*data.type(torch.FloatTensor)\n",
    "#data2=data-torch.mean(data.view(-1,data.size()[1]*data.size()[2]),0).view(28,28)\n",
    "#S=torch.std(data2.view(-1,data.size()[1]*data.size()[2]),0)\n",
    "#S[S==0]=1\n",
    "#data2=1.0/255*data2.view(-1,data.size()[1]*data.size()[2])\n",
    "#data2=data2.view(-1,28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### contrast normalize\n",
    "contrast_normalize_images=False\n",
    "if contrast_normalize_images:\n",
    "    n_d,p_dim,_=data.size()\n",
    "    norm=torch.max(torch.sum(data.view(n_d,-1)**2,1),torch.Tensor([0.00001]))\n",
    "    data=torch.div(data.view(n_d,-1),norm.view(n_d,1).expand(n_d,p_dim**2))\n",
    "    data=data.view(n_d,p_dim,p_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5e3043d1ac70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_d' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net=CKN()\n",
    "size_patch=3\n",
    "net=CKN(n_components=[150],n_layers=1,iter_max=50,n_patches=[size_patch],subsampling_factors=[2],batch_size=[60],center_patches=True)#Cell.fit_LBFGS(X)\n",
    "net.train_network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(net.Kernel[0].eta.data)\n",
    "self=net\n",
    "sb.heatmap(net.Kernel[0].W.data.numpy())\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.Kernel[0].convergence_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([ u.numpy() for u in net.Kernel[0].training_loss])\n",
    "#plt.plot([ u.numpy() for u in net.Kernel[1].training_loss],c='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(net.Kernel[0].output.size())\n",
    "sb.heatmap(net.Kernel[0].output[100,:100,:].numpy())\n",
    "print(X_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, pipeline\n",
    "from sklearn.kernel_approximation import (RBFSampler,\n",
    "                                          Nystroem)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "#X=net.Kernel[0].output\n",
    "X=net.Kernel[0].get_activation_map()\n",
    "n_p,n_d,p_dim=X.size()\n",
    "print(X.size())\n",
    "X=X.permute(1,0,2)\n",
    "print(X.size())\n",
    "\n",
    "pca_mnis=PCA(n_components=15,whiten=True)\n",
    "pca_mnis.fit(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "print(X.contiguous().view(n_d, n_p*p_dim).size())\n",
    "\n",
    "print(X.contiguous().size())\n",
    "X2=pca_mnis.transform(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "\n",
    "kernel_svm = svm.SVC(gamma=0.2)\n",
    "\n",
    "kernel_svm.fit(X2, X_labels.numpy())\n",
    "kernel_svm_score = kernel_svm.score(X2, X_labels.numpy())\n",
    "print(kernel_svm_score)\n",
    "\n",
    "X_test=train_loader.dataset.train_data[torch.LongTensor(inds[3000:6000])]\n",
    "X_test_labels=train_loader.dataset.train_labels[torch.LongTensor(inds[3000:6000])]\n",
    "\n",
    "X_test=1.0/255*X_test.type(torch.FloatTensor)\n",
    "n_d,p_dim,_=data.size()\n",
    "norm=torch.max(torch.sum(X_test.view(n_d,-1)**2,1),torch.Tensor([0.00001]))\n",
    "X_test=torch.div(X_test.view(n_d,-1),norm.view(n_d,1).expand(n_d,p_dim**2))\n",
    "X_test=X_test.view(n_d,p_dim,p_dim)\n",
    "print(X_test.size())\n",
    "X_test=extract_patches_from_image(X_test,size_patch)\n",
    "print(X_test.size())\n",
    "n_p,n_d,p_dim,_=X_test.size()\n",
    "X_test=X_test.view(n_p,n_d,p_dim*p_dim)\n",
    "output_test=net.propagate_through_network(X=X_test,patches_given=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_p,n_d,p_dim=X_test.size()\n",
    "XX=output_test\n",
    "print( 'XX size',XX.size())\n",
    "XX=XX.permute(1,0,2)\n",
    "print(XX.size())\n",
    "n_d,n_p,p_dim=XX.size()\n",
    "X_test1=pca_mnis.transform(X.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "X_test=pca_mnis.transform(XX.contiguous().view(n_d, n_p*p_dim).numpy())\n",
    "\n",
    "kernel_svm_score = kernel_svm.score(X_test, X_test_labels.numpy())\n",
    "print(kernel_svm_score)\n",
    "\n",
    "kernel_svm_score = kernel_svm.score(X2, X_labels.numpy())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

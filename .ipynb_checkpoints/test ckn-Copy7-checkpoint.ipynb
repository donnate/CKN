{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from CKN import *\n",
    "from Nystrom import *\n",
    "from image_processing_utils import *\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=train_loader.dataset.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.ByteTensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11c098610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFRCAYAAAAIKMaWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhsHoshERHZvP8PCofO8KLqmGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103e3d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAFRCAYAAAALn8i+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFRxJREFUeJzt3X9sVfX9x/HXuVx667jlV003NVobFnCQfCGSGIkTyqQ6\noasBeg0Fb5sJcdGZNaIZlhJQNm3hD2MMNGtHFlJY7KLrxsKYLOS6RjFoRwbTEkxgBQluJtYl9NZi\naXq/fzDv7JB7Sz+c3vPp5/lITkLvwY/vmI0X7/fnc871UqlUSgAAOCKU6wIAABhLBB8AwCkEHwDA\nKQQfAMApBB8AwCkEHwDAKWE/F/+/4kV+Lm+1J7+7NNclBNptNxfkuoTA+ujj3lyXEFg73j6Q6xIC\n7e9nO3xb2+TPez/r+jp0fAAAp/ja8QEA3OB5Xq5LGDGCDwBgzPPsGSDaUykAANcBHR8AwFhIjDoB\nAA6xaY+PUScAwCl0fAAAYyGLDrcQfAAAY4w6AQAIKDo+AIAxj1OdAACX2LTHZ0+lAABcB3R8AABj\nNh1uIfgAAMZCPgXf7373O7W3t8vzPH3xxRc6efKkDh8+rGg0KknavXu3Xn/9dU2fPl2StHXrVt1+\n++0Z1yT4AACBtXz5ci1fvlzS5VCrrKxMh54kdXV1afv27Zo9e/aI12SPDwBgzFNo1NdIvP/++zp1\n6pRisdiwz7u6utTc3KzVq1erpaVlRGvR8QEAjPm9x9fS0qInn3zyis+XLVumNWvWKBqN6sc//rE6\nOjq0aFHmb4On4wMABFpvb6/OnDmju+6664p7NTU1mjp1qsLhsBYtWqQTJ05kXY/gAwAYC3neqK9s\nOjs7dffdd1/xeTKZVHl5ufr7+5VKpXTkyBHNmTMn63qMOgEAxvx8c0t3d7duvfXW9M/79+9Xf3+/\nYrGY1q9fr3g8rkgkogULFmjhwoVZ1yP4AACBtnbt2mE/l5eXp39dUVGhioqKa1qP4AMAGLPplWUE\nHwDAmE1vbrEnogEAuA7o+AAAxvx6ZZkfCD4AgDGbvo+PUScAwCkj7viGhoYUCpGTAIArjZtTnefO\nnVNDQ4M++OADhcNhDQ0NaebMmaqrq1NJSclY1QgACDibTnVmDL76+no9/fTTmjt3bvqzY8eOqa6u\nTm1tbb4XBwDA9ZYx+AYGBoaFniTNmzfP14IAAPYZN6c6Z82apbq6Ot17770qKChQX1+fOjo6NGvW\nrLGqDwBgAZtOdWYMvueee06HDh3S0aNHlUwmFY1GtXjxYpWVlY1VfQAAXFcZg8/zPJWVlRF0AICM\nxs3hFgAARsKmPT57HrwAAOA6oOMDABgbN4dbAAAYCZve3GJPpQAAXAd0fAAAY5zqBAA4hVOdAAAE\nFB0fAMAYpzoBAE5h1AkAQEDR8QEAjHGqEwDgFEadAAAEFB0fAMAYpzoBAE5h1AkAQEDR8QEAjHGq\nEwDgFEadAAAEFB0fAMAYpzoBAE5h1AkAQEDR8QEAjHGqEwDgFEadAAAElK8d35PfXern8lZ74OE5\nuS4h0ApKvpXrEgLrO93/ynUJwBUYdQIAnGLT4wyMOgEATqHjAwAYC9nT8BF8AABzNu3xMeoEADiF\njg8AYMym5/gIPgCAMUadAAAEFB0fAMBYyKLn+Ag+AIAxP0edLS0tSiQSunTpklavXq2VK1em7yUS\nCTU1NSkcDmvlypWKxWJZ1yP4AACB9d577+lvf/ub2tra9Pnnn+tXv/pV+t7g4KAaGxvV3t6uSCSi\nqqoq3XfffZo+fXrGNdnjAwAYC3neqK9M3n77bc2cOVNPPPGEHn/8cS1evDh97/Tp0youLlY0GtXE\niRM1f/58dXZ2Zq2Vjg8AYMyvSee///1vffzxx2pubta5c+f0+OOP64033pAkJZNJFRQUpH/vpEmT\n1Nvbm3VNgg8AEFhTp07VjBkzFA6HVVJSokgkos8++0zTp09XNBpVMplM/96+vj5Nnjw565qMOgEA\nxvwadc6fP19vvfWWJOmTTz7RxYsXNW3aNEnSjBkzdPbsWV24cEEDAwPq7OzUvHnzstZKxwcAMObX\n1xKVlpbqr3/9qyorK5VKpbR582b98Y9/VH9/v2KxmOrq6vToo48qlUopFoupqKgo65oEHwAg0J55\n5pmr3istLVVpaek1rUfwAQCM2fTKMoIPAGCMl1QDAJxiUe5xqhMA4BY6PgCAMZtGnXR8AACn0PEB\nAIz59RyfHwg+AIAxm0adBB8AwJhFucceHwDALXR8AABjNr25hY4PAOAUOj4AgLFxc7glHo/r0qVL\nwz5LpVLyPE9tbW2+FgYAsIdFuZc5+J555hlt2rRJO3fu1IQJE8aqJgCAZcZNxzd37lw99NBD+vDD\nD1VWVjZWNQEA4Juse3zr1q0bizoAABaz6c0tnOoEADiFU50AAGM2PcdH8AEAjIXsyT2CDwBgzqaO\njz0+AIBT6PgAAMZs6vgIPgCAMZv2+Bh1AgCcQscHADDGqBMA4BSLco9RJwDALXR8AABj4+bbGQAA\nGAleUg0AQEDR8QEAjFk06ST4AADmbNrjY9QJAHAKHR8AwBgPsAMAnGJR7jHqBAC4hY4PAGCMUScA\nwCl8LREAAAFFxwcAMMaoEwDgFItyj1EnAMAtvnZ8t91c4OfyViso+VauSwi06O0luS4BFrrt5o9y\nXYKzbHplGaNOAIAxm/b4GHUCAJxCxwcAMGZRw0fwAQDMMeoEACCg6PgAAMYsavjo+AAA5kKeN+pr\nJHp6elRaWqru7u5hn+/evVvl5eWqrq5WdXW1zpw5k3UtOj4AQKANDg5qy5Ytys/Pv+JeV1eXtm/f\nrtmzZ494PTo+AIAxzxv9lc22bdtUVVWloqKiK+51dXWpublZq1evVktLy4hqJfgAAMY8zxv1lUl7\ne7sKCwt1zz33KJVKXXF/2bJlev7559Xa2qqjR4+qo6Mja60EHwAgsNrb23X48GHF43GdPHlSGzZs\nUE9PT/p+TU2Npk6dqnA4rEWLFunEiRNZ12SPDwBgzK9TnXv37k3/Oh6Pa+vWrSosLJQkJZNJlZeX\n609/+pPy8/N15MgRVVZWZl2T4AMAGBuLB9i//Hfs379f/f39isViWr9+veLxuCKRiBYsWKCFCxdm\nXYfgAwBYobW1VZJUUvLfb2+pqKhQRUXFNa1D8AEAjNn0ADvBBwAwZtP38XGqEwDgFDo+AIAxixo+\ngg8AYI6vJQIAIKDo+AAAxixq+Ag+AIA5Rp0AAAQUHR8AwJhFDR/BBwAwx6gTAICAouMDABizqOG7\n9uAbGBhQXl6eH7UAACw1LkadiURCixcvVllZmQ4cOJD+fN26dWNSGAAAfrhqx/eLX/xCv//97zU0\nNKTa2lp98cUXWr58uVKp1FjWBwCwgEUN39WDb+LEiZoyZYokqampSTU1NbrpppusamcBAGNjXHwt\n0S233KKGhgZ9/vnnikaj2rFjh7Zu3ap//OMfY1kfAMACnjf6a6xdNfhefPFFzZo1K93h3XTTTWpt\nbdWDDz44ZsUBAHC9XXXUGQ6HtWLFimGf3Xjjjaqvr/e9KACAXWzaBuMBdgCAU3iAHQBgzKKGj+AD\nAJjzQvYkH8EHADBmU8fHHh8AwCl0fAAAY5zqBAAgoOj4AADGLGr4CD4AgDmbRp0EHwDAmEW5xx4f\nAMAtdHwAAHMWtXx0fAAAp9DxAQCMcbgFAOAUi3KP4AMAmLPpJdXs8QEAnELHBwAwZtOok44PAOAU\nOj4AgDFOdQIAnGJR7hF8AABzNnV87PEBAJxCxwcAMGZRw0fHBwBwCx0fAMCYTXt8BB8AwJxF80Nf\ng++jj3v9XN5q3+n+V65LgKV6+d/OVfFnTu7Y1PFZlNEAAJhj1AkAMGZRw0fHBwAIrqGhIW3cuFFV\nVVVas2aNTp06Nex+IpFQZWWlVq1apddee21EaxJ8AABjnueN+sokkUjI8zy9+uqrqq2t1UsvvZS+\nNzg4qMbGRu3evVt79uzRb37zG3322WdZa2XUCQAw5teoc8mSJfre974nSTp//rymTJmSvnf69GkV\nFxcrGo1KkubPn6/Ozk498MADGdck+AAA5nzc5AuFQnr22Wd16NAhvfLKK+nPk8mkCgoK0j9PmjRJ\nvb3ZT/YSfACAwGtsbFRPT49isZgOHDig/Px8RaNRJZPJ9O/p6+vT5MmTs67FHh8AwJgX8kZ9ZbJv\n3z61tLRIkiKRiEKhkEKhy9E1Y8YMnT17VhcuXNDAwIA6Ozs1b968rLXS8QEAAuv+++9XXV2dHnnk\nEQ0ODmrjxo3685//rP7+fsViMdXV1enRRx9VKpVSLBZTUVFR1jUJPgCAMb+2+G644Qa9/PLLV71f\nWlqq0tLSa1qT4AMAGLPplWUEHwDAmEW5x+EWAIBb6PgAAOYsavno+AAATqHjAwAYy/Y8XpAQfAAA\nYxZNOgk+AMB1YFHysccHAHAKHR8AwJhFDR8dHwDALXR8AABjnOoEADiFd3UCANxiT+6xxwcAcAsd\nHwDAmE2jTjo+AIBTrqnju3jxokKhkPLy8vyqBwBgoXHT8Z06dUpPPPGE6urq9M4772jp0qVaunSp\n3nzzzbGqDwBgg5DBNcYydnxbtmxRbW2tzp8/r5/85Cc6ePCgIpGI1q1bp8WLF49VjQCAgLOp48sY\nfENDQ7rrrrskSe+++64KCwsv/0NhzsQAAOyUscksKSlRfX29hoaG1NjYKElqaWnRjTfeOCbFAQDs\n4HneqK+xlrF1+/nPf65EIqFQ6L/5+M1vflPxeNz3wgAA8EPG4AuFQlqyZMmwzx566CFfCwIAWMie\nLT4eYAcAmOMl1QAAt1h0qpM3twAAnELHBwAwZlHDR8cHAHALHR8AwNi4eXMLAAAjwqlOAIBLbOr4\n2OMDADiFjg8AYM6eho+ODwDgFjo+AIAxm/b4CD4AgDHe1QkAcAsdHwDAJTaNOjncAgBwCsEHAHAK\no04AgDl7Jp0EHwDAHKc6AQBusehwC8EHADDGqU4AAAKK4AMAOIVRJwDAHIdbAAAuYY8PAOAWz+Aa\ngePHjysej1/x+e7du1VeXq7q6mpVV1frzJkzWdfytePb8fYBP5fHOHbbzR/luoTA+ujj3lyXEFj8\nmZPZY9rg29p+dny7du3Svn37NGnSpCvudXV1afv27Zo9e/aI16PjAwAEWnFxsXbu3Pm197q6utTc\n3KzVq1erpaVlROsRfACAQCsrK9OECRO+9t6yZcv0/PPPq7W1VUePHlVHR0fW9Qg+AIC5kDf6y0BN\nTY2mTp2qcDisRYsW6cSJE9lLNfo3AgCgy3t8o71GKpVKDfs5mUyqvLxc/f39SqVSOnLkiObMmZN1\nHR5nAACYG4PHGb4Myf3796u/v1+xWEzr169XPB5XJBLRggULtHDhwqzrEHwAAGN+P8d3yy23qK2t\nTZJUXl6e/ryiokIVFRXXtBajTgCAUwg+AIBTGHUCAMzxrk4AgEtselcnwQcAMEfwAQBc4lk06uRw\nCwDAKQQfAMApjDoBAObY4wMAuIRTnQAAtxB8AACXcKoTAICAIvgAAE5h1AkAMMceHwDAKQQfAMAl\nPM4AAHALpzoBAAgmgg8A4BRGnQAAY55nTx814kp7enr8rAMAYDPPG/01xq7a8XV3dw/7ecOGDdq2\nbZskqaSkxN+qAABWGRenOn/4wx8qPz9fRUVFSqVS6u7u1ubNm+V5nlpbW8eyRgBA0I2HU52//e1v\n9e1vf1s/+tGPtGfPHt1xxx3as2cPoQcAsNpVO77CwkK9/PLL2rZtm95///2xrAkAAN9kPNwSDodV\nX1+fHncCAPB1PM8b9TXWRvQ4w4oVK7RixQq/awEA2Go8HG4BAGDELHqOj+ADABjjG9gBAAgogg8A\n4BRGnQAAcxxuAQC4ZFy8sgwAgBHjVCcAwCWc6gQAIKAIPgCAUxh1AgDMcbgFAOASTnUCANzCqU4A\ngFM41QkAQDARfAAApzDqBAAY43ALAMAtHG4BALiEjg8A4BaLOj57KgUA4Dog+AAATmHUCQAw5tfX\nEqVSKT333HP68MMPlZeXpxdeeEG33npr+n4ikVBTU5PC4bBWrlypWCyWdU2CDwBgzqfDLYcOHdLA\nwIDa2tp0/PhxNTQ0qKmpSZI0ODioxsZGtbe3KxKJqKqqSvfdd5+mT5+ecU1GnQAAY54XGvWVydGj\nR3XvvfdKkubOnasPPvggfe/06dMqLi5WNBrVxIkTNX/+fHV2dmatlY4PAGDOp44vmUyqoKAg/XM4\nHNbQ0JBCodAV9yZNmqTe3t6sa/oafH8/2+Hn8gAwzGPakOsSnJU3udCXdaPRqPr6+tI/fxl6X95L\nJpPpe319fZo8eXLWNRl1AgAC684771RHx+Um6tixY5o5c2b63owZM3T27FlduHBBAwMD6uzs1Lx5\n87Ku6aVSqZRvFQMAYOCrpzolqaGhQV1dXerv71csFtNf/vIX7dixQ6lUSpWVlaqqqsq6JsEHAHAK\no04AgFMIPgCAUwg+AIBTxn3wpVIpbdmyRatWrVJ1dbXOnTuX65IC6fjx44rH47kuI1AGBwf105/+\nVGvWrNHDDz+sRCKR65ICZWhoSBs3blRVVZXWrFmjU6dO5bqkwOnp6VFpaam6u7tzXQq+YtwH31df\nd/P000+roaEh1yUFzq5du7Rp0yZdunQp16UEyh/+8AdNmzZNv/71r/XLX/5SP/vZz3JdUqAkEgl5\nnqdXX31VtbW1eumll3JdUqAMDg5qy5Ytys/Pz3Up+B/jPvgyve4GlxUXF2vnzp25LiNwHnzwQdXW\n1kq63N2Ew7zo6KuWLFmS/svA+fPnNWXKlBxXFCzbtm1TVVWVioqKcl0K/se4D76rve4G/1VWVqYJ\nEybkuozAueGGG/SNb3xDyWRStbW1euqpp3JdUuCEQiE9++yzeuGFF/SDH/wg1+UERnt7uwoLC3XP\nPfeIJ8aCZ9wHX6bX3QDZ/POf/1RNTY2WL1+upUuX5rqcQGpsbNTBgwe1adMmXbx4MdflBEJ7e7sO\nHz6seDyukydPasOGDerp6cl1WfiPcT+7ufPOO/Xmm2/q+9///hWvu8Fw/M10uE8//VRr167V5s2b\ndffdd+e6nMDZt2+fPvnkEz322GOKRCIKhUL8pfI/9u7dm/51PB7X1q1bVVjoz7ssce3GffCVlZXp\n8OHDWrVqlSRxuCUDz6e3q9uqublZFy5cUFNTk3bu3CnP87Rr1y7l5eXlurRAuP/++1VXV6dHHnlE\ng4ODqq+v57/N1+D/V8HDK8sAAE5hLgEAcArBBwBwCsEHAHAKwQcAcArBBwBwCsEHAHAKwQcAcArB\nBwBwyv8D2VwzBOvP7JMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f9c2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(test[0,:,:].numpy())\n",
    "plt.figure()\n",
    "size_patch=5\n",
    "sb.heatmap(rel_distance_patch(size_patch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpt=test[0,:,:]\n",
    "sx,sy=inpt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_patch=5\n",
    "data=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_patch=5\n",
    "patches=extract_patches(data,size_patch, zero_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 60000, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_patch=[]        \n",
    "distances=[]\n",
    "X=data\n",
    "n_patches_per_graph=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=test[:1000,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Nystrom():\n",
    "    \n",
    "    def __init__(self,  n_components=50, iter_max=1000,random_state=None,size_patch=5,lr=0.001):\n",
    "        self.eta = Variable(torch.Tensor(1.0/n_components *(np.ones((n_components,)))),requires_grad=True)\n",
    "        self.W = torch.Tensor(Variable(None))\n",
    "        self.sigma=None\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.iter_max=iter_max\n",
    "        self.print_lag=15\n",
    "        self.lr=lr\n",
    "        self.training_data=None\n",
    "        self.size_patch=size_patch\n",
    "        self.patches=None\n",
    "        self.distances=None\n",
    "    \t\t\n",
    "    def select_training_patches(self,X,n_patches_per_graph,patches=None):\n",
    "        #### X should be  a tensor (3D)\n",
    "        #### select training patches within the same graph\n",
    "       # X_train=torch.Tensor((X.size()[0],n_patches_per_graph,size_patch**2,size_patch**2))\n",
    "        id_patch=[]        \n",
    "        distances=[]\n",
    "        n_patches_per_graph=10\n",
    "        for i in range(X.size()[0]):\n",
    "            ## select at random 2 nodes in the adjacency matrix:\n",
    "            a=X.size()[1]\n",
    "            for j in range(n_patches_per_graph):\n",
    "                nx,ny=np.random.choice(range(X.size()[1]*X.size()[2]),2)\n",
    "                distances+=[(nx%a-ny%a)**2+(nx//a-ny//a)**2]\n",
    "                id_patch+=[[i,nx,ny]]\n",
    "        if patches==None:\n",
    "            patches=extract_patches(data,size_patch, zero_padding=True)\n",
    "        selected_patches=torch.Tensor(len(id_patch),2,size_patch**2)\n",
    "        for j in range(len(id_patch)):\n",
    "\n",
    "            while torch.sum(patches[id_patch[j][1],id_patch[j][0],:])==0 and torch.sum(patches[id_patch[j][2],id_patch[j][0],:])==0:\n",
    "                nx,ny=np.random.choice(range(X.size()[1]*X.size()[2]),2)\n",
    "                id_patch[j]=[id_patch[j][0],nx,ny]\n",
    "            selected_patches[j,0,:]=patches[id_patch[j][1],id_patch[j][0],:]\n",
    "            selected_patches[j,1,:]=patches[id_patch[j][2],id_patch[j][0],:]\n",
    "            \n",
    "        return extract_selected_patches(X,id_patch, self.size_patch),distances,patches\n",
    "            \n",
    "        \n",
    "    def init_W(self,X):\n",
    "        self.training_data,self.distances,self.patches=self.select_training_patches(X,50)\n",
    "        distances2=torch.sum((self.training_data[:,0,:]-self.training_data[:,1,:])**2,dim=1)\n",
    "        if self.sigma==None:\n",
    "        \t### set to be quantile\n",
    "            ### compute the distance between patches\n",
    "            self.sigma=np.percentile(distances2.numpy(),10)\n",
    "        X_tilde=torch.cat((self.training_data[:,0,:],self.training_data[:,1,:]), dim=0)\n",
    "        print(self.sigma)\n",
    "        km=KMeans(n_clusters=self.n_components)\n",
    "        inds=range(int(X_tilde.size()[0]))\n",
    "        np.random.shuffle(inds)\n",
    "        X_tilde=X_tilde[list(inds[:np.min([4000,len(inds)])]),:]\n",
    "        km.fit(X_tilde.numpy())\n",
    "        self.W=Variable(torch.Tensor(km.cluster_centers_), requires_grad=True)\n",
    "    \t\t\t\n",
    "    def fit(self, X, y=None, init=True):\n",
    "        rnd = check_random_state(self.random_state)\n",
    "        D=self.n_components\n",
    "        if init==True: self.init_W(X)\n",
    "        X_input=Variable(self.training_data, requires_grad=False)\n",
    "        N=X_input.size()[0]\n",
    "        n=X_input.size()[1]\n",
    "        expected_output=Variable(torch.Tensor(torch.exp(-torch.sum((X_input[:,0,:]-X_input[:,1,:])**2/self.sigma,1))),requires_grad=False)\n",
    "        loss_func = nn.MSELoss()\n",
    "        optimizer = optim.SGD([self.W,self.eta], lr=self.lr) # instantiate optimizer with model params + learning rate (SGD for the moment)\n",
    "        for t in range(self.iter_max):\n",
    "            output=(X_input[:,0,:].repeat(1, D)-self.W.view(1,D*n).repeat(N, 1))**2+(X_input[:,1,:].repeat(1, D)-self.W.view(1,D*n).repeat(N, 1))**2\n",
    "            output2=output.view(N,D,n)\n",
    "            output2=torch.exp(-1.0/sigma*torch.sum(output2,2))\n",
    "            output2=torch.matmul(output2,self.eta)\n",
    "            loss=loss_func(output2,expected_output)\n",
    "            if t%self.print_lag==0: print(t, loss.data[0])\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            self.eta=Variable((self.eta).clamp(0,1000),requires_grad=True)\n",
    "        print('final loss is:',loss.data[0])\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def fit_LBFGS(self,X,init=True):\n",
    "        rnd = check_random_state(self.random_state)\n",
    "        D=self.n_components\n",
    "        if init==True: self.init_W(X)\n",
    "        print(\"Initialization: done\")\n",
    "        D=self.n_components\n",
    "        X_input=self.training_data\n",
    "        N=X_input.size()[0]\n",
    "        n=X_input.size()[1]\n",
    "        expected_output=Variable(torch.exp(-torch.sum((X_input[:,0,:]-X_input[:,1,:])**2/(2*self.sigma),1)),requires_grad=False)\n",
    "        X_input=Variable(X_input, requires_grad=False)\n",
    "        loss_func = nn.MSELoss()\n",
    "        optimizer = optim.LBFGS([self.W,self.eta]) # instantiate optimizer with model params + learning rate (SGD for the moment)\n",
    "        batch_size=100\n",
    "        sigma=self.sigma\n",
    "        output_tot=torch.Tensor()\n",
    "        for t in range(self.iter_max):\n",
    "            overall_loss=0\n",
    "            for b in range(batch_size):\n",
    "                def closure():\n",
    "                    XX=X_input[b*batch_size:(b+1)*batch_size,0,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "                    YY=X_input[b*batch_size:(b+1)*batch_size,1,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "                    output=(XX-self.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2+(YY-self.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2\n",
    "                    \n",
    "                    output=torch.sum(output.view(-1,p_size**2),1)\n",
    "                    output2=torch.exp(Variable(torch.Tensor(np.array([-1.0/sigma]))).expand_as(output)*output)\n",
    "                    #output2=torch.exp((-1.0/sigma).expand_as(output)*torch.sum(output.view(-1,p_size**2),1))\n",
    "                    weights=(2.0/(math.pi*sigma**2))**(D/2)*F.softmax(-self.eta)\n",
    "                    output2=torch.matmul(output2.view(-1,D),weights)\n",
    "                    loss=loss_func(output2,expected_output[b*batch_size:(b+1)*batch_size])\n",
    "                    #overall_loss+=loss[0]\n",
    "                    #if t%self.print_lag==0: print(t, loss.data[0])\n",
    "                    optimizer.zero_grad() \n",
    "                    loss.backward()\n",
    "                    #optimizer.step()\n",
    "                    \n",
    "                optimizer.step(closure)\n",
    "                self.eta=(self.eta).clamp(0,1000)\n",
    "            print(t,overall_loss)\n",
    "        \n",
    "    def _get_kernel_params(self):\n",
    "        params = self.kernel_params\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24866.6\n"
     ]
    }
   ],
   "source": [
    "Cell=Nystrom()\n",
    "Cell.init_W(X)\n",
    "#Cell.fit_LBFGS(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Variable containing:\n",
      " 1.6612\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1 Variable containing:\n",
      " 1.6585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2 Variable containing:\n",
      " 1.6565\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3 Variable containing:\n",
      " 1.6551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4 Variable containing:\n",
      " 1.6541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "5 Variable containing:\n",
      " 1.6533\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "6 Variable containing:\n",
      " 1.6526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "7 Variable containing:\n",
      " 1.6521\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "8 Variable containing:\n",
      " 1.6516\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "9 Variable containing:\n",
      " 1.6511\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "10 Variable containing:\n",
      " 1.6508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "11 Variable containing:\n",
      " 1.6505\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "12 Variable containing:\n",
      " 1.6502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "13 Variable containing:\n",
      " 1.6499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "14 Variable containing:\n",
      " 1.6496\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "15 Variable containing:\n",
      " 1.6494\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "16 Variable containing:\n",
      " 1.6492\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "17 Variable containing:\n",
      " 1.6490\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "18 Variable containing:\n",
      " 1.6489\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "19 Variable containing:\n",
      " 1.6487\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "20 Variable containing:\n",
      " 1.6486\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "21 Variable containing:\n",
      " 1.6484\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "22 Variable containing:\n",
      " 1.6483\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "23 Variable containing:\n",
      " 1.6482\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "24 Variable containing:\n",
      " 1.6481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "25 Variable containing:\n",
      " 1.6480\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "D=Cell.n_components\n",
    "X_input=Cell.training_data\n",
    "N=X_input.size()[0]\n",
    "n=X_input.size()[1]\n",
    "m=size_patch**2\n",
    "expected_output=Variable(torch.exp(torch.Tensor([-1.0/(2*Cell.sigma)])*torch.sum((X_input[:,0,:]-X_input[:,1,:])**2,1)),requires_grad=False)\n",
    "expected_output=1.0/torch.sqrt(torch.mean(expected_output**2))*expected_output\n",
    "X_input=Variable(X_input, requires_grad=False)\n",
    "loss_func = nn.MSELoss()\n",
    "#eta=Variable(torch.Tensor([1]*D),requires_grad=True)\n",
    "#W=Variable(W_storage.data,requires_grad=True)\n",
    "optimizer = optim.Adam([Cell.W,Cell.eta]) # instantiate optimizer with model params + learning rate (SGD for the moment)\n",
    "batch_size=100\n",
    "p_size=size_patch\n",
    "output_tot=torch.Tensor()\n",
    "\n",
    "for t in range(Cell.iter_max):\n",
    "        overall_loss=0\n",
    "    #def closure():\n",
    "        for b in range(batch_size):\n",
    "            #Cell.eta=F.relu(Cell.eta)\n",
    "            XX=X_input[b*batch_size:(b+1)*batch_size,0,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "            YY=X_input[b*batch_size:(b+1)*batch_size,1,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "            output=(XX-Cell.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2+(YY-Cell.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2\n",
    "            #output=(XX-Cell.W.view(D,1,p_size**2).expand(D,X_input.size()[0],p_size**2))**2+(X_input[:,1,:].repeat(1, D)-Cell.W.view(1,D*n).repeat(N, 1))**2\n",
    "            #output2=output.view(N,D,n)\n",
    "            output=torch.sum(output.view(-1,p_size**2),1)\n",
    "            #print(output[:10])\n",
    "            output2=torch.exp(Variable(torch.Tensor(np.array([-1.0/Cell.sigma]))).expand_as(output)*output)\n",
    "            \n",
    "            #output2=torch.exp((-1.0/sigma).expand_as(output)*torch.sum(output.view(-1,p_size**2),1))\n",
    "            #weights=C.expand_as(eta)*F.softmax(-eta)\n",
    "            output2=torch.matmul(output2.view(-1,D),F.relu(Cell.eta))\n",
    "            #print(output2[:10])\n",
    "            loss=loss_func(output2,expected_output[b*batch_size:(b+1)*batch_size])+1.0/batch_size*torch.sum((Cell.eta-F.relu(Cell.eta))**2)\n",
    "            #+0.1/D*torch.sum(Cell.eta)\n",
    "            #+2.0/D*torch.dot(Variable(torch.Tensor([1]*D)),Cell.eta)\n",
    "            overall_loss+=loss[0]\n",
    "            #STOP\n",
    "            #if t%Cell.print_lag==0: print(t, loss.data[0])\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            #Cell.eta=F.relu(Cell.eta)\n",
    "            \n",
    "            \n",
    "        #optimizer.step()\n",
    "        #Cell.eta=(Cell.eta).clamp(0,1000)\n",
    "        print(t,overall_loss/(60))\n",
    "        #print(eta[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(expected_output[b*batch_size:(b+1)*batch_size].data.numpy(), color='red')\n",
    "plt.hist(output2.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-02 *\n",
       "  9.7508\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(params, *args):\n",
    "    D=args[4]\n",
    "    #print(params)\n",
    "    W = params[:-D]\n",
    "    eta=params[-D:]\n",
    "    \n",
    "    W=W.reshape([D,-1])\n",
    "    eta=eta.reshape([D,1])\n",
    "    #print(W.shape)\n",
    "    XX = args[0]\n",
    "    YY = args[1]  #.reshape([100,25,1]),D)\n",
    "    sigma=args[2]\n",
    "    N=XX.shape[0]\n",
    "    expected_ouput = args[3]\n",
    "    test=np.array([((XX[i,:]-W)**2)+((YY[i,:]-W)**2)  for i in range(N)])\n",
    "    #print((np.exp(-1.0/sigma*np.sum(test,2))).shape)\n",
    "    #print(eta.shape)\n",
    "    res=(expected_ouput_t -((eta.T).dot(np.exp(-1.0/sigma*np.sum(test,2)))))\n",
    "    return np.sum(res**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-5cec3be9a562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpected_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got Variable"
     ]
    }
   ],
   "source": [
    "expected_output=Variable(torch.exp(Variable(torch.Tensor([-1.0/(2*sigma)]))*torch.sum((X_input[:,0,:]-X_input[:,1,:])**2,1)),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1074\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(output2,expected_output[b*batch_size:(b+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-8d08e88b18c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesty2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
     ]
    }
   ],
   "source": [
    "testy2=np.array([((testy[i,:]-W.data.numpy())**2)+((testy[i,:]-W.data.numpy())**2) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2381\n",
       "-0.0000\n",
       " 0.0141\n",
       " 0.0976\n",
       " 0.0166\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0418\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0651\n",
       "-0.0000\n",
       " 0.0223\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0277\n",
       " 0.0203\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0000\n",
       " 0.0075\n",
       " 0.0509\n",
       "-0.0000\n",
       " 0.0054\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0510\n",
       " 0.0813\n",
       " 0.0202\n",
       " 0.0306\n",
       "-0.0000\n",
       " 0.0157\n",
       " 0.0334\n",
       "-0.0000\n",
       " 0.0154\n",
       " 0.0514\n",
       "-0.0000\n",
       " 0.0721\n",
       " 0.0203\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0072\n",
       " 0.0000\n",
       " 0.0712\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0480\n",
       "-0.0000\n",
       " 0.0705\n",
       " 0.0095\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0000\n",
       "-0.0000\n",
       " 0.0198\n",
       "-0.0000\n",
       " 0.0888\n",
       " 0.0555\n",
       "-0.0000\n",
       " 0.1483\n",
       " 0.0407\n",
       " 0.0907\n",
       "-0.0000\n",
       " 0.0218\n",
       " 0.0044\n",
       "-0.0000\n",
       " 0.0486\n",
       "-0.0000\n",
       " 0.0085\n",
       " 0.0398\n",
       " 0.0066\n",
       "-0.0000\n",
       " 0.0868\n",
       "-0.0000\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0127\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0583\n",
       " 0.0346\n",
       " 0.0041\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0643\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0567\n",
       " 0.0662\n",
       "-0.0000\n",
       "-0.0000\n",
       " 0.0000\n",
       " 0.0104\n",
       " 0.0022\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cell.eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args=(X_input[b*batch_size:(b+1)*batch_size,0,:].data.numpy(),\\\n",
    "      X_input[b*batch_size:(b+1)*batch_size,1,:].data.numpy(),\\\n",
    "      Cell.sigma,\\\n",
    "      expected_ouput_t,\\\n",
    "      100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.04238892,  0.32662582,  0.30661392, ...,  0.01      ,\n",
       "        0.01      ,  0.01      ])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_values = np.array(list(Cell.W.data.numpy().reshape([-1,]))+list(Cell.eta.data))\n",
    "mybounds = [(None,None)]*2500+[(0,None)]*100\n",
    "x,f,d = scipy.optimize.fmin_l_bfgs_b(func, x0=initial_values, args=args, bounds=mybounds,approx_grad=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068295918279463033"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (100,25) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-e5ffb948e114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmybounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (100,25) "
     ]
    }
   ],
   "source": [
    "mybounds = [(None,None)*np.ones(Cell.W.data.shape), [(0,None)]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.2866e-01\n",
       " 1.0041e-02\n",
       " 3.2957e-08\n",
       "          \n",
       " 9.6713e-01\n",
       " 5.6344e-01\n",
       " 3.9064e-08\n",
       "[torch.FloatTensor of size 10000]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.Tensor([-1.0/(2*sigma)])*torch.sum((X_input[:,0,:]-X_input[:,1,:])**2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX=X_input[b*batch_size:(b+1)*batch_size,0,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "YY=X_input[b*batch_size:(b+1)*batch_size,1,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=XX.shape[0]\n",
    "test=np.array([((W.numpy()-XX[i,:])**2)+((YY[i,:]-W.numpy())**2)  for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (100,25) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-04cc25089b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_ouput_t\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (100,25) "
     ]
    }
   ],
   "source": [
    "res=(expected_ouput_t -((eta.numpy().T).dot(np.exp(-1.0/sigma*np.sum(test,2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Wfinal=x[:-D].reshape([D,25])\n",
    "etafinal=x[-D:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.array([((Wfinal-XX[i,:])**2)+((YY[i,:]-Wfinal)**2)  for i in range(N)])\n",
    "testy2=((etafinal.T).dot(np.exp(-1.0/sigma*np.sum(test,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### convergence feels super long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma=Cell.sigma\n",
    "XX=X_input[b*batch_size:(b+1)*batch_size,0,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "YY=X_input[b*batch_size:(b+1)*batch_size,1,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "output=(XX-W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2+(YY-W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2\n",
    "            #output=(XX-Cell.W.view(D,1,p_size**2).expand(D,X_input.size()[0],p_size**2))**2+(X_input[:,1,:].repeat(1, D)-Cell.W.view(1,D*n).repeat(N, 1))**2\n",
    "            #output2=output.view(N,D,n)\n",
    "output=torch.sum(output.view(-1,p_size**2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2=torch.exp(Variable(torch.Tensor(np.array([-1.0/sigma]))).expand_as(output)*output)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX,YY,sigma=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       ..., \n",
       "       [ 143.,    0.,    0., ...,  252.,  253.,  252.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([Cell.W,Cell.eta], lr=0.001) # instantiate optimizer with model params + learning rate (SGD for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.351002693176\n"
     ]
    }
   ],
   "source": [
    "b=0\n",
    "#for b in range(batch_size):\n",
    "if True:\n",
    "    XX=X_input[b*batch_size:(b+1)*batch_size,0,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "    YY=X_input[b*batch_size:(b+1)*batch_size,1,:].contiguous().view((1,batch_size,p_size**2)).expand(D,batch_size,p_size**2)\n",
    "    output=(XX-Cell.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2+(YY-Cell.W.view(D,1,p_size**2).expand(D,batch_size,p_size**2))**2\n",
    "    #output=(XX-Cell.W.view(D,1,p_size**2).expand(D,X_input.size()[0],p_size**2))**2+(X_input[:,1,:].repeat(1, D)-Cell.W.view(1,D*n).repeat(N, 1))**2\n",
    "    #output2=output.view(N,D,n)\n",
    "    output=torch.sum(output.view(-1,p_size**2),1)\n",
    "    output2=torch.exp(Variable(torch.Tensor(np.array([-1.0/sigma]))).expand_as(output)*output)\n",
    "    #output2=torch.exp((-1.0/sigma).expand_as(output)*torch.sum(output.view(-1,p_size**2),1))\n",
    "    output2=torch.matmul(output2.view(-1,D),Cell.eta)\n",
    "    loss=loss_func(output2,expected_output[b*batch_size:(b+1)*batch_size])\n",
    "    if t%Cell.print_lag==0: print(t, loss.data[0])\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    #optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-12635.1045\n",
       "-50090.0312\n",
       "-44346.5547\n",
       "-39612.2695\n",
       "-27825.7812\n",
       "-32192.5918\n",
       "-38866.4844\n",
       "-37411.7344\n",
       "-35703.8984\n",
       "-16458.9219\n",
       "-41367.4766\n",
       "-26044.8555\n",
       "-22595.2207\n",
       "-22862.3535\n",
       "-35012.9180\n",
       "-76053.4297\n",
       "-53471.5234\n",
       "-47059.4727\n",
       "-16618.3633\n",
       "-35342.5625\n",
       "-23153.2148\n",
       "-53424.2891\n",
       "-57006.1172\n",
       "-29867.5879\n",
       "-22765.9590\n",
       "-33376.5430\n",
       "-23692.9297\n",
       "-35117.8672\n",
       "-31196.3789\n",
       "-48068.2188\n",
       "-64642.2344\n",
       "-29950.3418\n",
       "-46447.3086\n",
       "-30474.5430\n",
       "-18114.9570\n",
       "-36398.8242\n",
       "-42714.1797\n",
       "-16337.1104\n",
       "-30705.0430\n",
       "-42055.5586\n",
       "-44140.5352\n",
       "-17189.9160\n",
       "-57467.8984\n",
       "-17486.7773\n",
       "-38252.7070\n",
       "-17331.3926\n",
       "-42414.9375\n",
       "-35207.1133\n",
       "-34459.3438\n",
       "-39640.7031\n",
       "-45195.2852\n",
       "-17414.5586\n",
       "-21393.0059\n",
       "-53992.0625\n",
       "-23719.8047\n",
       "-49569.9688\n",
       "-46881.2031\n",
       "-26782.0078\n",
       "-45832.4492\n",
       "-44100.4883\n",
       "-51174.8125\n",
       "-31048.8594\n",
       "-50664.1875\n",
       "-31295.4258\n",
       "-28567.5234\n",
       "-42744.3711\n",
       "-64276.3750\n",
       "-59786.0078\n",
       "-26140.0039\n",
       "-32354.8008\n",
       "-41725.5000\n",
       "-54907.3047\n",
       "-31312.4297\n",
       "-13542.4492\n",
       "-43348.3984\n",
       "-14151.0078\n",
       "-30320.5977\n",
       "-18862.2207\n",
       "-35328.1172\n",
       "-13483.6934\n",
       "-13641.0820\n",
       "-68638.5938\n",
       "-49641.3672\n",
       "-34233.3203\n",
       "-24038.9961\n",
       "-34769.5664\n",
       "-29230.4570\n",
       "-32101.0723\n",
       "-47202.8750\n",
       "-45896.5625\n",
       "-30751.6641\n",
       "-24276.8809\n",
       "-15757.0723\n",
       "-31991.7344\n",
       "-49281.3281\n",
       "-46263.2305\n",
       "-53380.2891\n",
       "-16980.0840\n",
       "-37946.6680\n",
       "-34582.6719\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output=torch.sum(output.view(-1,p_size**2),1)\n",
    "output2=Variable(torch.Tensor(np.array([-1.0/sigma]))).expand_as(output)*output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e+06 *\n",
       " -3.0943\n",
       " -3.0463\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0611\n",
       " -3.0446\n",
       " -2.7925\n",
       " -3.0029\n",
       " -3.0943\n",
       " -2.7368\n",
       " -3.0691\n",
       " -2.7046\n",
       " -2.9883\n",
       " -3.0183\n",
       " -3.0943\n",
       " -2.9696\n",
       " -2.6035\n",
       " -2.9257\n",
       " -3.0074\n",
       " -2.8651\n",
       " -2.7925\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0046\n",
       " -3.0943\n",
       " -2.7365\n",
       " -3.0903\n",
       " -2.9015\n",
       " -2.7776\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0751\n",
       " -2.8067\n",
       " -3.0286\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -2.8944\n",
       " -3.0943\n",
       " -2.5852\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0740\n",
       " -3.0317\n",
       " -3.0489\n",
       " -2.8551\n",
       " -2.8880\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0554\n",
       " -2.8224\n",
       " -3.0005\n",
       " -3.0943\n",
       " -2.8446\n",
       " -2.8325\n",
       " -3.0529\n",
       " -2.9813\n",
       " -2.9105\n",
       " -3.2127\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0815\n",
       " -3.0384\n",
       " -3.0135\n",
       " -2.7727\n",
       " -3.0943\n",
       " -3.0839\n",
       " -2.9591\n",
       " -3.0182\n",
       " -2.9870\n",
       " -3.0218\n",
       " -3.0943\n",
       " -2.7607\n",
       " -3.0163\n",
       " -3.0943\n",
       " -2.9693\n",
       " -3.0943\n",
       " -2.9093\n",
       " -3.0397\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0943\n",
       " -3.0622\n",
       " -3.0943\n",
       " -2.8985\n",
       " -2.6454\n",
       " -3.0943\n",
       " -3.0943\n",
       " -2.9534\n",
       " -3.0943\n",
       " -2.9566\n",
       " -2.7685\n",
       " -3.0688\n",
       " -2.8501\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cell.eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   0.8645    0.1428    0.1343  ...     0.0905    0.2128    0.5653\n",
       "   0.0000    8.0000  116.5714  ...   149.2143   23.0714   13.4286\n",
       "   6.4167    0.0000    2.1250  ...    17.9167  155.5000  233.8333\n",
       "             ...                                ...             \n",
       "  18.0909    0.0000   -0.0000  ...    88.4091   23.7727   29.8182\n",
       " 213.1429  239.7143  184.5000  ...     1.5000   15.0714   10.4286\n",
       "  66.0000   47.0000    0.0000  ...   208.0000   13.0000    0.0000\n",
       "[torch.FloatTensor of size 100x25]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cell.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_image=data.size()[1:]\n",
    "selected_patches=torch.Tensor(len(id_patch),2,size_patch**2)\n",
    "for j in range(len(id_patch)):\n",
    "        selected_patches[j,0,:]=patches[id_patch[j][1],id_patch[j][0],:]\n",
    "        selected_patches[j,1,:]=patches[id_patch[j][2],id_patch[j][0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_selected_patches(data,id_patch,size_patch, zero_padding=True):\n",
    "    \n",
    "    size_image=data.size()[1:]\n",
    "    center_x=id_patch[1]//size_image[0]\n",
    "    center_y=id_patch[1]%size_image[0]\n",
    "    selected_patches=torch.Tensor((len(id_patches),2,size_patch**2))\n",
    "    patches=extract_patches(data,size_patch, zero_padding=True)\n",
    "    for j in range(len(id_patch)):\n",
    "        selected_patches[j,0,:]=patches[center_x[j],id_patch[j][0],:]\n",
    "        selected_patches[j,1,:]=patches[center_y[j],id_patch[j][0],:]\n",
    "    return patches[id_patch[0],center_x,center_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "size_image=data.size()[1:]\n",
    "a=size_patch+size_image[0]\n",
    "b=size_patch+size_image[1]\n",
    "padded_image=torch.Tensor(np.zeros((data.size()[0],a,b)))\n",
    "padded_image[:,size_patch//2:(size_patch//2)+size_image[0],size_patch//2:(size_patch//2)+size_image[1]]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx,ny=padded_image.size()[1:]\n",
    "patches=torch.Tensor(np.array([padded_image[:,ii:ii+size_patch,jj:jj+size_patch].numpy() for ii in np.arange(0,nx-size_patch,1) for jj in np.arange(0,ny-size_patch,1) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches=patches.view([patches.size()[0],patches.size()[1],size_patch**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=test\n",
    "size_patch=5\n",
    "import numpy as np\n",
    "patches=extract_patches(data,size_patch, zero_padding=True)\n",
    "patches=patches.view([patches.size()[0],patches.size()[1],size_patch**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_shape=size_patch\n",
    "#spacing=np.min([p_shape, data.size()[2]//p_shape]) \n",
    "spacing=p_shape//2\n",
    "gamma=2\n",
    "D=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches[100,30,:].norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W=torch.Tensor(np.random.sample(D*size_patch**2).reshape([D,size_patch**2]))\n",
    "\n",
    "eta=torch.Tensor(np.random.dirichlet([1.0/D]*D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_p,n_d=patches.size()[:2]\n",
    "norm = torch.Tensor(np.array([patches[i,j,:].norm(p=2) for i in range(n_p) for j in range(n_d)]))\n",
    "\n",
    "norm2 = patches.view((n_p*n_d,size_patch**2)).norm(p=2,dim=1).view((n_p,n_d,1))\n",
    "\n",
    "norm3=torch.max(norm2, torch.Tensor(np.ones(norm2.size())))\n",
    "\n",
    "norm_patches=patches.div(norm3.expand_as(patches))\n",
    "\n",
    "W2=W.expand(n_d*n_p,D,25)\n",
    "norm_patches2=norm_patches.view((n_d*n_p,1,size_patch**2)).expand(n_d*n_p,D,size_patch**2)\n",
    "batch_size=10000\n",
    "testy=torch.Tensor((n_d*n_p*D))\n",
    "output2=torch.Tensor((n_d*n_p*D))\n",
    "sigma=1\n",
    "\n",
    "\n",
    "\n",
    "for b in range(n_d*n_p//batch_size):\n",
    "    print(b)\n",
    "    testy[b*batch_size*D:(b+1)*batch_size*D]=torch.sum(((norm_patches2[b*batch_size:(b+1)*batch_size,:,:]\\\n",
    "            -W.expand_as(norm_patches2[b*batch_size:(b+1)*batch_size,:,:]))**2).contiguous().view((-1,25)),dim=1)\n",
    "    \n",
    "    output2[b*batch_size*D:(b+1)*batch_size*D]=torch.exp(-1.0/sigma*testy[b*batch_size*D:(b+1)*batch_size*D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2=testy.view(n_p,n_d,D)\n",
    "sigma=1\n",
    "output2=torch.exp(-1.0/sigma*output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output2=torch.matmul(output2,eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeta=norm.view((n_d,n_p))*(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output2=torch.matmul(output2,eta)\n",
    "#zeta=norm.mmul(output2)\n",
    "#patches=[c.reshape([1,-1]) for c in extract_patches_2d(zeta.numpy(),[p_shape,p_shape])]\n",
    "beta=gamma*spacing  ### what is that spacing? Where is it defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_map=2.0/np.sqrt(math.pi)*torch.sum(torch.exp(-1.0/beta*torch.Tensor(model_patch))*zeta,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output2=output.view(N,p_shape**2,D)\n",
    "output2=torch.exp(-1.0/self.Kernels[id_map].sigma*torch.sum(output2,1))\n",
    "output2=torch.matmul(output2,self.Kernels[id_map].eta)\n",
    "zeta=norm.mmul(output2)\n",
    "patches=[c.reshape([1,-1]) for c in extract_patches_2d(zeta.numpy(),[p_shape,p_shape])]\n",
    "beta=gamma*spacing  ### what is that spacing? Where is it defined?\n",
    "output_map=self.model_patch[k]*patches\n",
    "return output_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    ### start by extracting patches from image\n",
    "    patches=[c.reshape([1,-1]) for c in extract_patches_2d(xi.numpy(),[p_shape,p_shape])]\n",
    "    patches=torch.Tensor(patches)\n",
    "    patches=patches.squeeze()\n",
    "    ### subsamples patches?\n",
    "    \n",
    "    ### l2 normalized version of the patches\n",
    "    norm = patches.norm(p=2, dim=0, keepdim=True)\n",
    "    norm_patches=patches.div(norm.expand_as(patches))\n",
    "    N=norm_patches.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activation_map(im,xi,id_map):\n",
    "    ### have to generalize this guy to take as input lots of images in the right tensor shape\n",
    "    p_shape=self.patch_shape[id_map]\n",
    "    spacing=np.min([im.size()[0]//p_shape, im.size()[1]//p_shape]) \n",
    "    gamma=2\n",
    "    D=self.Kernels[id_map].n_components\n",
    "    ### start by extracting patches from image\n",
    "    patches=[c.reshape([1,-1]) for c in extract_patches_2d(xi.numpy(),[p_shape,p_shape])]\n",
    "    patches=torch.Tensor(patches)\n",
    "    patches=patches.squeeze()\n",
    "    ### subsamples patches?\n",
    "    \n",
    "    ### l2 normalized version of the patches\n",
    "    norm = patches.norm(p=2, dim=0, keepdim=True)\n",
    "    norm_patches=patches.div(norm.expand_as(patches))\n",
    "    N=norm_patches.size()[0]\n",
    "    output=(norm_patches.repeat(1, D).view(N,p_shape**2,D)-self.Kernels[id_map].W.view(p_shape**2,D).repeat(0, N))**2\n",
    "    output2=output.view(N,p_shape**2,D)\n",
    "    output2=torch.exp(-1.0/self.Kernels[id_map].sigma*torch.sum(output2,1))\n",
    "    output2=torch.matmul(output2,self.Kernels[id_map].eta)\n",
    "    zeta=norm.mmul(output2)\n",
    "    patches=[c.reshape([1,-1]) for c in extract_patches_2d(zeta.numpy(),[p_shape,p_shape])]\n",
    "    beta=gamma*spacing  ### what is that spacing? Where is it defined?\n",
    "    output_map=self.model_patch[k]*patches\n",
    "    return output_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
